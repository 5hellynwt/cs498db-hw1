{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\ndataset = []\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        dataset.append(pd.read_csv(os.path.join(dirname, filename)))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-02T04:58:48.095758Z","iopub.execute_input":"2022-02-02T04:58:48.096424Z","iopub.status.idle":"2022-02-02T04:58:48.977092Z","shell.execute_reply.started":"2022-02-02T04:58:48.096372Z","shell.execute_reply":"2022-02-02T04:58:48.976171Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Question 1: Average of likes:\nnlikes_ds = []\nfor ds in dataset:\n    nlikes_ds.append(pd.DataFrame.mean(ds[\"nlikes\"]))\n\navg_likes = np.mean(nlikes_ds)\nprint(\"The average of likes is:\", avg_likes)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:58:48.979965Z","iopub.execute_input":"2022-02-02T04:58:48.980518Z","iopub.status.idle":"2022-02-02T04:58:48.997690Z","shell.execute_reply.started":"2022-02-02T04:58:48.980465Z","shell.execute_reply":"2022-02-02T04:58:48.996229Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"'''\nQ2:\nFrom the above, estimate how many people view one\nof his tweets, on average. Assume that engagement rate, \ncalculated by summing likes, replies, and retweets, and dividing \nby views, is roughly .05 for any given tweet.\n'''\n\nviews_ds = []\nfor ds in dataset:\n    eng = pd.DataFrame.sum(ds[\"nlikes\"]) + pd.DataFrame.sum(ds[\"nreplies\"]) + pd.DataFrame.sum(ds[\"nretweets\"])\n    views_ds.append(eng / ( 0.05 * len(ds) ))\n\navg_views = np.mean(views_ds)\nprint(avg_views)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:58:48.999868Z","iopub.execute_input":"2022-02-02T04:58:49.000516Z","iopub.status.idle":"2022-02-02T04:58:49.022330Z","shell.execute_reply.started":"2022-02-02T04:58:49.000464Z","shell.execute_reply":"2022-02-02T04:58:49.021371Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"'''\nQuestion 3: Estimate the average amount of data (in megabytes) \nstored for each Elon Musk tweet. Consider the sizes and types of \nany attached media.\n'''\npic_size = 10 * 10**(3) # size of 1 pic in bytes\nvid_size = 2.49 * 10**6 # size of 18s video of 480p \n\nfile_size = []\nfor ds in dataset:\n    num_pics = 0\n    for pic in ds[\"photos\"]:\n        num_pics += len(pic)\n        \n    ds_size = num_pics * pic_size\n    \n    for vid in ds[\"video\"]:\n        if vid == 1:\n            ds_size += vid_size\n            \n    file_size.append(ds_size / len(ds))\n\navg_datapertwt = np.mean(file_size)\nprint(avg_datapertwt)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:58:49.025314Z","iopub.execute_input":"2022-02-02T04:58:49.026158Z","iopub.status.idle":"2022-02-02T04:58:49.067575Z","shell.execute_reply.started":"2022-02-02T04:58:49.026051Z","shell.execute_reply":"2022-02-02T04:58:49.066187Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"'''\nQuestion 4: Using the answers above, estimate the total data \ntransfer involved in displaying any given Elon Musk tweet to \nTwitter users.\n'''\n\ntotal_datatrf = avg_views * avg_datapertwt\nprint(total_datatrf)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:58:49.069195Z","iopub.execute_input":"2022-02-02T04:58:49.070128Z","iopub.status.idle":"2022-02-02T04:58:49.078206Z","shell.execute_reply.started":"2022-02-02T04:58:49.070092Z","shell.execute_reply":"2022-02-02T04:58:49.077175Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"'''\nQuestion 5: Estimate how many Elon tweets are viewed, per-\nminute, by the site's userbase.\n'''\n\nminutes_11yrs = 525600 * 11 # number of minutes in the span of 11 years\n\ntotal_views = 0\nfor ds in dataset:\n    eng = pd.DataFrame.sum(ds[\"nlikes\"]) + pd.DataFrame.sum(ds[\"nreplies\"]) + pd.DataFrame.sum(ds[\"nretweets\"])\n    total_views += (eng / 0.05)\n    \nviews_permin = total_views / minutes_11yrs\nprint(views_permin)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:58:49.080383Z","iopub.execute_input":"2022-02-02T04:58:49.080718Z","iopub.status.idle":"2022-02-02T04:58:49.095787Z","shell.execute_reply.started":"2022-02-02T04:58:49.080675Z","shell.execute_reply":"2022-02-02T04:58:49.094557Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"'''\nQuestion 6: Using the above, estimate how much data is accessed \nper-minute by Twitter in the process of displaying Elon Musk \ntweets.\n'''\n\navg_datapertwt = views_permin * avg_datapertwt\nprint(avg_datapertwt)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:58:49.098171Z","iopub.execute_input":"2022-02-02T04:58:49.098551Z","iopub.status.idle":"2022-02-02T04:58:49.106945Z","shell.execute_reply.started":"2022-02-02T04:58:49.098506Z","shell.execute_reply":"2022-02-02T04:58:49.105978Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"'''\nQuestion 7:  You do not need to submit this answer in \nAnswers.txt. At the end of your Python notebook, choose a \nfunction that involves modifying a tweet (say, updating its 'likes' \ncount, which you can assume is cached in a tweet's associated \ndatabase row). How much data do you believe is touched by this \noperation on a monthly basis? Consider the amount of data \naffected, the frequency at which the operation is carried out, and \nso on.\n'''\n\n# Operation: Updating likes for one tweet\n\n# The total data to modify likes:\nint_size = 4 # the size of an integer in bytes (32-bit). Data used to change the number of likes\nimg_size = 1500 # estimated size of the heart image to like\ntotal_data = int_size + img_size\n\n# Since the data for average likes (from Q1) spans for 11 years:\nmonths_11yrs = 12 * 11\n\n# And the average number of likes per month is:\navg_likespermonth = avg_likes / months_11yrs\n\n# Then the total data touched by the operation per month is:\navg_data_monthly = total_data * avg_likespermonth\n\nprint(avg_data_monthly)","metadata":{"execution":{"iopub.status.busy":"2022-02-02T04:58:49.108314Z","iopub.execute_input":"2022-02-02T04:58:49.108648Z","iopub.status.idle":"2022-02-02T04:58:49.149539Z","shell.execute_reply.started":"2022-02-02T04:58:49.108599Z","shell.execute_reply":"2022-02-02T04:58:49.148313Z"},"trusted":true},"execution_count":9,"outputs":[]}]}